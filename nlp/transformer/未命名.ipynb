{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math, copy, time\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "seaborn.set_context(context=\"talk\")\n",
    "%matplotlib inline\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型整体架构\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "结构图如下：\n",
    "<img src=\"https://tva1.sinaimg.cn/large/e6c9d24egy1h4i5wv3zfwj20qi0xkdik.jpg\" alt=\"image-20220724175041623\" style=\"zoom:67%;height:800px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d82881c5d0d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"Core encoder is a stack of N layers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
    "    \n",
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "<img src=\"https://tva1.sinaimg.cn/large/e6c9d24egy1h4igx84ucsj20qs1180w0.jpg\" alt=\"image-20220725001134489\" style=\"zoom:67%;height:800px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 1 1 1 1 1 1 1]\n",
      "  [0 0 1 1 1 1 1 1]\n",
      "  [0 0 0 1 1 1 1 1]\n",
      "  [0 0 0 0 1 1 1 1]\n",
      "  [0 0 0 0 0 1 1 1]\n",
      "  [0 0 0 0 0 0 1 1]\n",
      "  [0 0 0 0 0 0 0 1]\n",
      "  [0 0 0 0 0 0 0 0]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASsAAAEvCAYAAAAdNeeiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAANP0lEQVR4nO3d3Ytch33G8efJWiaRYmMqb4P10iqBIAiBrsygEgSmtdNIbozTi15IkEBCYXvRBJsWgtObkn8gpBclIGSnLnFsEjuCEFxvTBPjGhrZK3mTWJYcHOHizSbRRiHYcmiEN08vduTOrne1Z6s5c+ZnfT+weF+GmQchf3XOzOyMkwgAxt27uh4AAE0QKwAlECsAJRArACUQKwAlECsAJVzXxpXe/AcT2bN7SxtXvSk/+dHWricA2IT/0Ru6lN95rZ+1Eqs9u7fo2ZndbVz1phzcMdX1BACbcCL/se7POA0EUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlBCo1jZPmT7Jdsv276v7VEAsNqGsbI9IelfJN0p6UOSjtj+UNvDAGBQkyOr/ZJeTnIuySVJj0j6RLuzAGClJrHaKenVga/n+98DgJFpEqu1XgjrbW82aHva9qzt2cULS1e/DAAGNInVvKTBV9LbJWlh9YWSHE3SS9Kb3D4xrH0AIKlZrJ6T9EHb77d9vaTDkr7d7iwAWGnDlzVO8qbtz0qakTQh6YEkp1tfBgADGr0Ge5LHJT3e8hYAWBfPYAdQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlBCo19krmpmYa7rCZKkgzumup4AlMeRFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBI2jJXtB2yft/3CKAYBwFqaHFn9q6RDLe8AgCvaMFZJnpb06xFsAYB1cZ8VgBKGFivb07Znbc8uXlga1tUCgKQhxirJ0SS9JL3J7RPDuloAkMRpIIAimjx14WFJ/yVpr+1523/T/iwAWGnDN4xIcmQUQwDgSjgNBFACsQJQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUMKGv8iMqzezMNf1BEnSwR1TXU8A/t84sgJQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlACsQJQArECUAKxAlBCk7eP3237+7bP2D5t+55RDAOAQU1edeFNSf+Q5JTtGySdtP1kkhdb3gYAb9nwyCrJz5Oc6n/+uqQzkna2PQwABm3qPivbeyTtk3SijTEAsJ7GsbL9XkmPSbo3yWtr/Hza9qzt2cULS8PcCADNYmV7i5ZD9VCSb611mSRHk/SS9Ca3TwxzIwA0ejTQku6XdCbJl9qfBABv1+TI6oCkT0m63fZc/+MvW94FACts+NSFJM9I8gi2AMC6eAY7gBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEpq8BjveIWYW5rqeIEk6uGOq6wkoiCMrACUQKwAlECsAJRArACUQKwAlECsAJRArACUQKwAlECsAJRArACUQKwAlECsAJWwYK9vvtv2s7R/aPm37i6MYBgCDmrzqwu8k3Z7kou0tkp6x/e9JftDyNgB4y4axShJJF/tfbul/pM1RALBao/usbE/YnpN0XtKTSU60OwsAVmoUqyRLSaYk7ZK03/aHV1/G9rTtWduzixeWhr0TwDVuU48GJvmNpKckHVrjZ0eT9JL0JrdPDGkeACxr8mjgpO2b+p+/R9JHJZ1texgADGryaOAtkh60PaHluH0jyXfanQUAKzV5NPBHkvaNYAsArItnsAMogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASihyasuAEM1szDX9QRJ0sEdU11PwCZwZAWgBGIFoARiBaAEYgWgBGIFoARiBaAEYgWgBGIFoARiBaAEYgWgBGIFoARiBaCExrGyPWH7edu8dTyAkdvMkdU9ks60NQQArqRRrGzvkvRxScfanQMAa2t6ZPVlSZ+X9PsWtwDAujaMle27JJ1PcnKDy03bnrU9u3hhaWgDAUBqdmR1QNLdtl+R9Iik221/bfWFkhxN0kvSm9w+MeSZAK51G8YqyReS7EqyR9JhSd9L8snWlwHAAJ5nBaCETb1hRJKnJD3VyhIAuAKOrACUQKwAlECsAJRArACUQKwAlECsAJRArACUQKwAlECsAJRArACUQKwAlECsAJSwqV9kBt5JZhbmup4gSTq4Y6rrCSVwZAWgBGIFoARiBaAEYgWgBGIFoARiBaAEYgWgBGIFoARiBaAEYgWgBGIFoARiBaCERr/IbPsVSa9LWpL0ZpJem6MAYLXNvOrCnyf5VWtLAOAKOA0EUELTWEXSd22ftD3d5iAAWEvT08ADSRZs/6GkJ22fTfL04AX6EZuWpD/ayWv6ARiuRkdWSRb6/z0v6bik/Wtc5miSXpLe5PaJ4a4EcM3bMFa2t9m+4fLnkj4m6YW2hwHAoCbna++TdNz25ct/PckTra4CgFU2jFWSc5L+ZARbAGBdPHUBQAnECkAJxApACcQKQAnECkAJxApACcQKQAnECkAJxApACcQKQAnECkAJxApACbxKHtCxmYW5ridIkg7umOp6whVxZAWgBGIFoARiBaAEYgWgBGIFoARiBaAEYgWgBGIFoARiBaAEYgWgBGIFoARiBaCERrGyfZPtR22ftX3G9kfaHgYAg5q+6sI/S3oiyV/bvl7S1hY3AcDbbBgr2zdKuk3SpyUpySVJl9qdBQArNTkN/ICkRUlftf287WO2t7W8CwBWaBKr6yTdKukrSfZJekPSfasvZHva9qzt2cULS0OeCeBa1yRW85Lmk5zof/2oluO1QpKjSXpJepPbJ4a5EQA2jlWSX0h61fbe/rfukPRiq6sAYJWmjwZ+TtJD/UcCz0n6THuTAODtGsUqyZykXstbAGBdPIMdQAnECkAJxApACcQKQAnECkAJxApACcQKQAnECkAJxApACcQKQAnECkAJxApACU1fdQHAO9zMwlzXE7T/4G/X/RlHVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAErYMFa299qeG/h4zfa9oxgHAJdt+KoLSV6SNCVJtick/UzS8ZZ3AcAKmz0NvEPST5P8dxtjAGA9m43VYUkPtzEEAK6kcaxsXy/pbknfXOfn07Znbc8uXlga1j4AkLS5I6s7JZ1K8su1fpjkaJJekt7k9onhrAOAvs3E6og4BQTQkUaxsr1V0l9I+la7cwBgbY3eMCLJbyVtb3kLAKyLZ7ADKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYASiBWAEowUmGf6X2oqSrfenjmyX9aghzrhY7xmuDxI7V3kk7/jjJ5Fo/aCVWw2B7NkmPHeOzYxw2sOPa3cFpIIASiBWAEsY5Vke7HtDHjv8zDhskdqx2TewY2/usAGDQOB9ZAcBbxi5Wtg/Zfsn2y7bv62jDA7bP236hi9sf2LHb9vdtn7F92vY9He14t+1nbf+wv+OLXewY2DNh+3nb3+lwwyu2f2x7zvZshztusv2o7bP9vycf6WDD3v6fw+WP12zfO/TbGafTQNsTkn6i5XfSmZf0nKQjSV4c8Y7bJF2U9G9JPjzK21614xZJtyQ5ZfsGSScl/VUHfx6WtC3JRdtbJD0j6Z4kPxjljoE9fy+pJ+nGJHd1tOEVSb0knT6/yfaDkv4zybH+GxFvTfKbDvdMSPqZpD9NcrXPtVxh3I6s9kt6Ocm5JJckPSLpE6MekeRpSb8e9e2usePnSU71P39d0hlJOzvYkSQX+19u6X908q+c7V2SPi7pWBe3P05s3yjpNkn3S1KSS12Gqu8OST8ddqik8YvVTkmvDnw9rw7+5xxHtvdI2ifpREe3P2F7TtJ5SU8m6WSHpC9L+ryk33d0+5dF0ndtn7Q93dGGD0halPTV/mnxMdvbOtpy2WG19GbI4xYrr/G98TlP7Yjt90p6TNK9SV7rYkOSpSRTknZJ2m975KfHtu+SdD7JyVHf9hoOJLlV0p2S/q5/18GoXSfpVklfSbJP0huSOrmfV5L6p6F3S/pmG9c/brGal7R74OtdkhY62jIW+vcRPSbpoSSdvyN2/zTjKUmHOrj5A5Lu7t9f9Iik221/rYMdSrLQ/+95Sce1fBfGqM1Lmh84yn1Uy/Hqyp2STiX5ZRtXPm6xek7SB22/v1/pw5K+3fGmzvTv2L5f0pkkX+pwx6Ttm/qfv0fSRyWdHfWOJF9IsivJHi3/3fhekk+Oeoftbf0HPNQ/7fqYpJE/cpzkF5Jetb23/607JI30wZdVjqilU0Cp4dvHj0qSN21/VtKMpAlJDyQ5Peodth+W9GeSbrY9L+mfktw/6h1aPpL4lKQf9+8vkqR/TPL4iHfcIunB/iM975L0jSSdPW1gDLxP0vHlf0t0naSvJ3mioy2fk/RQ/x/3c5I+08UI21u1/Cj+37Z2G+P01AUAWM+4nQYCwJqIFYASiBWAEogVgBKIFYASiBWAEogVgBKIFYAS/hf/gBPgamfA0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    print(subsequent_mask)\n",
    "    return torch.from_numpy(subsequent_mask) == 0\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(subsequent_mask(8)[0])\n",
    "None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention\n",
    "<img src=\"https://tva1.sinaimg.cn/large/e6c9d24egy1h4iuhkco06j20a60ek0t2.jpg\" alt=\"image-20220725080058237\" style=\"zoom:50%;\" />\n",
    "<img src=\"https://tva1.sinaimg.cn/large/e6c9d24egy1h4iuipgyibj20k804o74e.jpg\" alt=\"image-20220725080204901\" style=\"zoom:70%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Head Attention\n",
    "<img src=\"https://tva1.sinaimg.cn/large/e6c9d24egy1h4jj3y8sqej20em0ii3zd.jpg\" alt=\"image-20220725221249513\" style=\"zoom:67%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1d9beb30efaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mPositionwiseFeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"Implements FFN equation.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPositionwiseFeedForward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings and Softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-1efcf88c9ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Small example model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtmp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1efcf88c9ff0>\u001b[0m in \u001b[0;36mmake_model\u001b[0;34m(src_vocab, tgt_vocab, N, d_model, d_ff, h, dropout)\u001b[0m\n\u001b[1;32m      2\u001b[0m                d_model=512, d_ff=2048, h=8, dropout=0.1):\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Helper: Construct a model from hyperparameters.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadedAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPositionwiseFeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_ff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'copy' is not defined"
     ]
    }
   ],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model\n",
    "\n",
    "# Small example model.\n",
    "tmp_model = make_model(10, 10, 2)\n",
    "None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
